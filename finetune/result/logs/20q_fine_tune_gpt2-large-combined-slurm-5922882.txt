/work/anshitagupta_umass_edu/miniconda3/envs/memit/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 4060
  Num Epochs = 2
  Instantaneous batch size per device = 64
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 128
Loaded dataset with 4060 elements
Loaded dataset with 1004 elements
  0%|          | 0/128 [00:00<?, ?it/s]  1%|          | 1/128 [00:02<04:19,  2.04s/it]  2%|â–         | 2/128 [00:03<03:53,  1.85s/it]  2%|â–         | 3/128 [00:05<03:43,  1.79s/it]  3%|â–Ž         | 4/128 [00:07<03:38,  1.76s/it]  4%|â–         | 5/128 [00:08<03:34,  1.75s/it]  5%|â–         | 6/128 [00:10<03:31,  1.74s/it]  5%|â–Œ         | 7/128 [00:12<03:29,  1.73s/it]  6%|â–‹         | 8/128 [00:14<03:27,  1.73s/it]  7%|â–‹         | 9/128 [00:15<03:25,  1.73s/it]  8%|â–Š         | 10/128 [00:17<03:23,  1.72s/it]  9%|â–Š         | 11/128 [00:19<03:21,  1.72s/it]  9%|â–‰         | 12/128 [00:20<03:19,  1.72s/it] 10%|â–ˆ         | 13/128 [00:22<03:18,  1.72s/it] 11%|â–ˆ         | 14/128 [00:24<03:16,  1.72s/it] 12%|â–ˆâ–        | 15/128 [00:26<03:14,  1.72s/it] 12%|â–ˆâ–Ž        | 16/128 [00:27<03:12,  1.72s/it] 13%|â–ˆâ–Ž        | 17/128 [00:29<03:11,  1.72s/it] 14%|â–ˆâ–        | 18/128 [00:31<03:09,  1.72s/it] 15%|â–ˆâ–        | 19/128 [00:33<03:07,  1.72s/it] 16%|â–ˆâ–Œ        | 20/128 [00:34<03:05,  1.72s/it] 16%|â–ˆâ–‹        | 21/128 [00:36<03:04,  1.72s/it] 17%|â–ˆâ–‹        | 22/128 [00:38<03:02,  1.72s/it] 18%|â–ˆâ–Š        | 23/128 [00:39<03:00,  1.72s/it] 19%|â–ˆâ–‰        | 24/128 [00:41<02:58,  1.72s/it] 20%|â–ˆâ–‰        | 25/128 [00:43<02:57,  1.72s/it] 20%|â–ˆâ–ˆ        | 26/128 [00:45<02:55,  1.72s/it] 21%|â–ˆâ–ˆ        | 27/128 [00:46<02:53,  1.72s/it] 22%|â–ˆâ–ˆâ–       | 28/128 [00:48<02:51,  1.72s/it] 23%|â–ˆâ–ˆâ–Ž       | 29/128 [00:50<02:50,  1.72s/it] 23%|â–ˆâ–ˆâ–Ž       | 30/128 [00:51<02:48,  1.72s/it] 24%|â–ˆâ–ˆâ–       | 31/128 [00:53<02:46,  1.72s/it] 25%|â–ˆâ–ˆâ–Œ       | 32/128 [00:55<02:45,  1.72s/it] 26%|â–ˆâ–ˆâ–Œ       | 33/128 [00:57<02:43,  1.72s/it] 27%|â–ˆâ–ˆâ–‹       | 34/128 [00:58<02:41,  1.72s/it] 27%|â–ˆâ–ˆâ–‹       | 35/128 [01:00<02:40,  1.72s/it] 28%|â–ˆâ–ˆâ–Š       | 36/128 [01:02<02:38,  1.72s/it] 29%|â–ˆâ–ˆâ–‰       | 37/128 [01:03<02:36,  1.72s/it] 30%|â–ˆâ–ˆâ–‰       | 38/128 [01:05<02:34,  1.72s/it] 30%|â–ˆâ–ˆâ–ˆ       | 39/128 [01:07<02:33,  1.72s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 40/128 [01:09<02:31,  1.72s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 41/128 [01:10<02:29,  1.72s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 42/128 [01:12<02:28,  1.72s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 43/128 [01:14<02:26,  1.72s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 44/128 [01:16<02:24,  1.72s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 45/128 [01:17<02:23,  1.72s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 46/128 [01:19<02:21,  1.72s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 47/128 [01:21<02:19,  1.72s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 48/128 [01:22<02:17,  1.72s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 49/128 [01:24<02:16,  1.72s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 50/128 [01:26<02:14,  1.72s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 51/128 [01:28<02:12,  1.72s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 52/128 [01:29<02:11,  1.73s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 53/128 [01:31<02:09,  1.73s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 54/128 [01:33<02:07,  1.73s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 55/128 [01:35<02:05,  1.73s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 56/128 [01:36<02:04,  1.73s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 57/128 [01:38<02:02,  1.73s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 58/128 [01:40<02:00,  1.73s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 59/128 [01:41<01:59,  1.73s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 60/128 [01:43<01:57,  1.73s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 61/128 [01:45<01:55,  1.73s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 62/128 [01:47<01:53,  1.73s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 63/128 [01:48<01:52,  1.73s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 64/128 [01:49<01:37,  1.52s/it]***** Running Evaluation *****
  Num examples = 1004
  Batch size = 64

  0%|          | 0/16 [00:00<?, ?it/s][A
 12%|â–ˆâ–Ž        | 2/16 [00:00<00:03,  4.44it/s][A
 19%|â–ˆâ–‰        | 3/16 [00:00<00:04,  3.13it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:01<00:04,  2.72it/s][A
 31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:01<00:04,  2.52it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:02<00:04,  2.41it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:02<00:03,  2.35it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:03<00:03,  2.30it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:03<00:03,  2.28it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 10/16 [00:04<00:02,  2.26it/s][A
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:04<00:02,  2.25it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:04<00:01,  2.23it/s][A
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:05<00:01,  2.23it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:05<00:00,  2.23it/s][A
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:06<00:00,  2.22it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:06<00:00,  2.34it/s][A                                                
                                               [A 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 64/128 [01:57<01:37,  1.52s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:06<00:00,  2.34it/s][A
                                               [ASaving model checkpoint to results/checkpoints/20q/gpt2-large/combined/checkpoint-64
Configuration saved in results/checkpoints/20q/gpt2-large/combined/checkpoint-64/config.json
Model weights saved in results/checkpoints/20q/gpt2-large/combined/checkpoint-64/pytorch_model.bin
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 65/128 [03:25<31:07, 29.64s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 66/128 [03:26<21:58, 21.26s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 67/128 [03:28<15:39, 15.40s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 68/128 [03:30<11:17, 11.30s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 69/128 [03:31<08:17,  8.42s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 70/128 [03:33<06:11,  6.41s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 71/128 [03:35<04:45,  5.01s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 72/128 [03:37<03:45,  4.02s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 73/128 [03:38<03:03,  3.33s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 74/128 [03:40<02:33,  2.85s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 75/128 [03:42<02:13,  2.51s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 76/128 [03:44<01:58,  2.27s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 77/128 [03:45<01:47,  2.11s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 78/128 [03:47<01:39,  1.99s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 79/128 [03:49<01:33,  1.91s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 80/128 [03:50<01:29,  1.85s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 81/128 [03:52<01:25,  1.81s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 82/128 [03:54<01:22,  1.79s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 83/128 [03:56<01:19,  1.77s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 84/128 [03:57<01:17,  1.75s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 85/128 [03:59<01:15,  1.75s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 86/128 [04:01<01:13,  1.74s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 87/128 [04:02<01:11,  1.74s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 88/128 [04:04<01:09,  1.73s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 89/128 [04:06<01:07,  1.73s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 90/128 [04:08<01:05,  1.73s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 91/128 [04:09<01:03,  1.73s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 92/128 [04:11<01:02,  1.73s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 93/128 [04:13<01:00,  1.73s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 94/128 [04:15<00:58,  1.73s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 95/128 [04:16<00:56,  1.73s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 96/128 [04:18<00:55,  1.73s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 97/128 [04:20<00:53,  1.73s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 98/128 [04:21<00:51,  1.73s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 99/128 [04:23<00:50,  1.73s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 100/128 [04:25<00:48,  1.73s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 101/128 [04:27<00:46,  1.73s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 102/128 [04:28<00:44,  1.73s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 103/128 [04:30<00:43,  1.73s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 104/128 [04:32<00:41,  1.73s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 105/128 [04:34<00:39,  1.73s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 106/128 [04:35<00:37,  1.73s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 107/128 [04:37<00:36,  1.73s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 108/128 [04:39<00:34,  1.73s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 109/128 [04:40<00:32,  1.73s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 110/128 [04:42<00:31,  1.73s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 111/128 [04:44<00:29,  1.73s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 112/128 [04:46<00:27,  1.72s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 113/128 [04:47<00:25,  1.72s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 114/128 [04:49<00:24,  1.72s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 115/128 [04:51<00:22,  1.72s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 116/128 [04:53<00:20,  1.72s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 117/128 [04:54<00:18,  1.72s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 118/128 [04:56<00:17,  1.72s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 119/128 [04:58<00:15,  1.72s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 120/128 [04:59<00:13,  1.72s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 121/128 [05:01<00:12,  1.73s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 122/128 [05:03<00:10,  1.73s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 123/128 [05:05<00:08,  1.73s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 124/128 [05:06<00:06,  1.73s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 125/128 [05:08<00:05,  1.73s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 126/128 [05:10<00:03,  1.73s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 127/128 [05:12<00:01,  1.73s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [05:13<00:00,  1.52s/it]***** Running Evaluation *****
  Num examples = 1004
  Batch size = 64
{'eval_loss': 1.0075840950012207, 'eval_runtime': 7.1376, 'eval_samples_per_second': 140.663, 'eval_steps_per_second': 2.242, 'epoch': 1.0}

  0%|          | 0/16 [00:00<?, ?it/s][A
 12%|â–ˆâ–Ž        | 2/16 [00:00<00:03,  4.44it/s][A
 19%|â–ˆâ–‰        | 3/16 [00:00<00:04,  3.13it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:01<00:04,  2.71it/s][A
 31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:01<00:04,  2.52it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:02<00:04,  2.41it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:02<00:03,  2.34it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:03<00:03,  2.30it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:03<00:03,  2.27it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 10/16 [00:04<00:02,  2.26it/s][A
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:04<00:02,  2.24it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:04<00:01,  2.24it/s][A
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:05<00:01,  2.23it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:05<00:00,  2.23it/s][A
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:06<00:00,  2.22it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:06<00:00,  2.34it/s][A                                                 
                                               [A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [05:20<00:00,  1.52s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:06<00:00,  2.34it/s][A
                                               [ASaving model checkpoint to results/checkpoints/20q/gpt2-large/combined/checkpoint-128
Configuration saved in results/checkpoints/20q/gpt2-large/combined/checkpoint-128/config.json
Model weights saved in results/checkpoints/20q/gpt2-large/combined/checkpoint-128/pytorch_model.bin
Deleting older checkpoint [results/checkpoints/20q/gpt2-large/combined/checkpoint-192] due to args.save_total_limit


Training completed. Do not forget to share your model on huggingface.co/models =)


Loading best model from results/checkpoints/20q/gpt2-large/combined/checkpoint-64 (score: 1.0075840950012207).
                                                 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [07:21<00:00,  1.52s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [07:21<00:00,  3.45s/it]
***** Running Evaluation *****
  Num examples = 1004
  Batch size = 64
{'eval_loss': 1.0217806100845337, 'eval_runtime': 7.1395, 'eval_samples_per_second': 140.627, 'eval_steps_per_second': 2.241, 'epoch': 2.0}
{'train_runtime': 441.4723, 'train_samples_per_second': 18.393, 'train_steps_per_second': 0.29, 'train_loss': 1.059881567955017, 'epoch': 2.0}
  0%|          | 0/16 [00:00<?, ?it/s] 12%|â–ˆâ–Ž        | 2/16 [00:00<00:03,  4.44it/s] 19%|â–ˆâ–‰        | 3/16 [00:00<00:04,  3.13it/s] 25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:01<00:04,  2.71it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:01<00:04,  2.52it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:02<00:04,  2.41it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:02<00:03,  2.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:03<00:03,  2.30it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:03<00:03,  2.28it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 10/16 [00:04<00:02,  2.26it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:04<00:02,  2.25it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:04<00:01,  2.24it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:05<00:01,  2.23it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:05<00:00,  2.23it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:06<00:00,  2.23it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:06<00:00,  2.34it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:06<00:00,  2.38it/s]
Saving model checkpoint to results/best-checkpoints/20q/gpt2-large/combined
Configuration saved in results/best-checkpoints/20q/gpt2-large/combined/config.json
Model weights saved in results/best-checkpoints/20q/gpt2-large/combined/pytorch_model.bin
{'eval_loss': 1.0075840950012207, 'eval_runtime': 7.1279, 'eval_samples_per_second': 140.856, 'eval_steps_per_second': 2.245, 'epoch': 2.0}
Loaded dataset with 4060 elements
Loaded dataset with 1004 elements
Loaded dataset with 5055 elements
train Accuracy =  0.9820197044334975
train F1 score =  0.9833344369901622
train Confusion Matrix =  [[1946   61]
 [   1 2041]]
Classification Report               precision    recall  f1-score   support

        6407       1.00      0.97      0.98      2014
       10352       0.97      1.00      0.98      2046

   micro avg       0.98      0.98      0.98      4060
   macro avg       0.99      0.98      0.98      4060
weighted avg       0.99      0.98      0.98      4060

valid Accuracy =  0.9880478087649402
valid F1 score =  0.9890230712337263
valid Confusion Matrix =  [[491   9]
 [  1 501]]
Classification Report               precision    recall  f1-score   support

        6407       1.00      0.98      0.99       502
       10352       0.98      1.00      0.99       502

   micro avg       0.99      0.99      0.99      1004
   macro avg       0.99      0.99      0.99      1004
weighted avg       0.99      0.99      0.99      1004

test Accuracy =  0.9782393669634025
test F1 score =  0.9794822908177926
test Confusion Matrix =  [[2416   83]
 [  14 2529]]
Classification Report               precision    recall  f1-score   support

        6407       0.99      0.96      0.98      2507
       10352       0.97      0.99      0.98      2548

   micro avg       0.98      0.98      0.98      5055
   macro avg       0.98      0.98      0.98      5055
weighted avg       0.98      0.98      0.98      5055

