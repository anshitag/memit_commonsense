/work/anshitagupta_umass_edu/miniconda3/envs/memit/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 4060
  Num Epochs = 2
  Instantaneous batch size per device = 64
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 128
Loaded dataset with 4060 elements
Loaded dataset with 1004 elements
  0%|          | 0/128 [00:00<?, ?it/s]  1%|          | 1/128 [00:02<04:26,  2.10s/it]  2%|â–         | 2/128 [00:03<03:22,  1.61s/it]  2%|â–         | 3/128 [00:04<03:01,  1.45s/it]  3%|â–Ž         | 4/128 [00:05<02:51,  1.38s/it]  4%|â–         | 5/128 [00:07<02:45,  1.35s/it]  5%|â–         | 6/128 [00:08<02:41,  1.32s/it]  5%|â–Œ         | 7/128 [00:09<02:38,  1.31s/it]  6%|â–‹         | 8/128 [00:11<02:36,  1.30s/it]  7%|â–‹         | 9/128 [00:12<02:34,  1.30s/it]  8%|â–Š         | 10/128 [00:13<02:33,  1.30s/it]  9%|â–Š         | 11/128 [00:14<02:31,  1.30s/it]  9%|â–‰         | 12/128 [00:16<02:30,  1.30s/it] 10%|â–ˆ         | 13/128 [00:17<02:29,  1.30s/it] 11%|â–ˆ         | 14/128 [00:18<02:28,  1.30s/it] 12%|â–ˆâ–        | 15/128 [00:20<02:27,  1.30s/it] 12%|â–ˆâ–Ž        | 16/128 [00:21<02:25,  1.30s/it] 13%|â–ˆâ–Ž        | 17/128 [00:22<02:24,  1.30s/it] 14%|â–ˆâ–        | 18/128 [00:24<02:23,  1.31s/it] 15%|â–ˆâ–        | 19/128 [00:25<02:22,  1.31s/it] 16%|â–ˆâ–Œ        | 20/128 [00:26<02:22,  1.31s/it] 16%|â–ˆâ–‹        | 21/128 [00:28<02:20,  1.32s/it] 17%|â–ˆâ–‹        | 22/128 [00:29<02:20,  1.32s/it] 18%|â–ˆâ–Š        | 23/128 [00:30<02:19,  1.33s/it] 19%|â–ˆâ–‰        | 24/128 [00:32<02:18,  1.33s/it] 20%|â–ˆâ–‰        | 25/128 [00:33<02:17,  1.33s/it] 20%|â–ˆâ–ˆ        | 26/128 [00:34<02:16,  1.34s/it] 21%|â–ˆâ–ˆ        | 27/128 [00:36<02:15,  1.34s/it] 22%|â–ˆâ–ˆâ–       | 28/128 [00:37<02:14,  1.34s/it] 23%|â–ˆâ–ˆâ–Ž       | 29/128 [00:38<02:12,  1.34s/it] 23%|â–ˆâ–ˆâ–Ž       | 30/128 [00:40<02:11,  1.34s/it] 24%|â–ˆâ–ˆâ–       | 31/128 [00:41<02:10,  1.35s/it] 25%|â–ˆâ–ˆâ–Œ       | 32/128 [00:42<02:09,  1.35s/it] 26%|â–ˆâ–ˆâ–Œ       | 33/128 [00:44<02:08,  1.35s/it] 27%|â–ˆâ–ˆâ–‹       | 34/128 [00:45<02:06,  1.35s/it] 27%|â–ˆâ–ˆâ–‹       | 35/128 [00:46<02:05,  1.35s/it] 28%|â–ˆâ–ˆâ–Š       | 36/128 [00:48<02:04,  1.35s/it] 29%|â–ˆâ–ˆâ–‰       | 37/128 [00:49<02:02,  1.35s/it] 30%|â–ˆâ–ˆâ–‰       | 38/128 [00:50<02:01,  1.35s/it] 30%|â–ˆâ–ˆâ–ˆ       | 39/128 [00:52<02:00,  1.35s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 40/128 [00:53<01:59,  1.36s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 41/128 [00:55<01:58,  1.36s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 42/128 [00:56<01:56,  1.35s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 43/128 [00:57<01:55,  1.35s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 44/128 [00:59<01:55,  1.37s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 45/128 [01:00<01:53,  1.37s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 46/128 [01:01<01:51,  1.37s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 47/128 [01:03<01:50,  1.36s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 48/128 [01:04<01:48,  1.36s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 49/128 [01:05<01:47,  1.36s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 50/128 [01:07<01:47,  1.38s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 51/128 [01:08<01:45,  1.37s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 52/128 [01:10<01:43,  1.37s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 53/128 [01:11<01:42,  1.37s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 54/128 [01:12<01:40,  1.36s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 55/128 [01:14<01:39,  1.36s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 56/128 [01:15<01:39,  1.38s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 57/128 [01:16<01:37,  1.37s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 58/128 [01:18<01:35,  1.37s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 59/128 [01:19<01:34,  1.37s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 60/128 [01:20<01:32,  1.37s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 61/128 [01:22<01:31,  1.36s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 62/128 [01:23<01:31,  1.38s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 63/128 [01:25<01:29,  1.38s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 64/128 [01:25<01:18,  1.22s/it]***** Running Evaluation *****
  Num examples = 1004
  Batch size = 64

  0%|          | 0/16 [00:00<?, ?it/s][A
 12%|â–ˆâ–Ž        | 2/16 [00:00<00:02,  5.73it/s][A
 19%|â–ˆâ–‰        | 3/16 [00:00<00:03,  4.04it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:01<00:03,  3.50it/s][A
 31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:01<00:03,  3.24it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:01<00:03,  3.08it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:02<00:03,  2.99it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:02<00:02,  2.93it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:02<00:02,  2.90it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 10/16 [00:03<00:02,  2.87it/s][A
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:03<00:01,  2.85it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:03<00:01,  2.84it/s][A
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:04<00:01,  2.83it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:04<00:00,  2.83it/s][A
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:04<00:00,  2.82it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:05<00:00,  3.08it/s][A                                                
                                               [A 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 64/128 [01:31<01:18,  1.22s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:05<00:00,  3.08it/s][A
                                               [ASaving model checkpoint to results/checkpoints/20q/gpt2-xl/combined/checkpoint-64
Configuration saved in results/checkpoints/20q/gpt2-xl/combined/checkpoint-64/config.json
Model weights saved in results/checkpoints/20q/gpt2-xl/combined/checkpoint-64/pytorch_model.bin
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 65/128 [04:44<1:03:17, 60.28s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 66/128 [04:45<43:59, 42.57s/it]   52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 67/128 [04:46<30:40, 30.18s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 68/128 [04:47<21:30, 21.50s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 69/128 [04:49<15:10, 15.43s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 70/128 [04:50<10:48, 11.19s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 71/128 [04:51<07:48,  8.21s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 72/128 [04:52<05:43,  6.13s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 73/128 [04:54<04:17,  4.68s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 74/128 [04:55<03:17,  3.66s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 75/128 [04:56<02:36,  2.95s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 76/128 [04:58<02:07,  2.46s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 77/128 [04:59<01:47,  2.11s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 78/128 [05:00<01:33,  1.87s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 79/128 [05:02<01:23,  1.70s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 80/128 [05:03<01:15,  1.58s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 81/128 [05:04<01:10,  1.50s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 82/128 [05:05<01:06,  1.44s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 83/128 [05:07<01:03,  1.40s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 84/128 [05:08<01:00,  1.37s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 85/128 [05:09<00:58,  1.35s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 86/128 [05:11<00:56,  1.35s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 87/128 [05:12<00:54,  1.34s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 88/128 [05:13<00:53,  1.34s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 89/128 [05:15<00:52,  1.33s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 90/128 [05:16<00:50,  1.34s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 91/128 [05:17<00:49,  1.34s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 92/128 [05:19<00:48,  1.34s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 93/128 [05:20<00:46,  1.34s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 94/128 [05:21<00:45,  1.34s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 95/128 [05:23<00:44,  1.34s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 96/128 [05:24<00:42,  1.34s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 97/128 [05:25<00:41,  1.35s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 98/128 [05:27<00:40,  1.35s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 99/128 [05:28<00:39,  1.35s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 100/128 [05:29<00:37,  1.34s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 101/128 [05:31<00:36,  1.35s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 102/128 [05:32<00:35,  1.35s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 103/128 [05:34<00:33,  1.35s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 104/128 [05:35<00:32,  1.35s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 105/128 [05:36<00:31,  1.35s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 106/128 [05:38<00:29,  1.35s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 107/128 [05:39<00:28,  1.36s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 108/128 [05:40<00:27,  1.35s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 109/128 [05:42<00:25,  1.35s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 110/128 [05:43<00:24,  1.35s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 111/128 [05:44<00:22,  1.35s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 112/128 [05:46<00:21,  1.37s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 113/128 [05:47<00:20,  1.37s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 114/128 [05:49<00:19,  1.37s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 115/128 [05:50<00:17,  1.37s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 116/128 [05:51<00:16,  1.38s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 117/128 [05:53<00:15,  1.37s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 118/128 [05:54<00:13,  1.37s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 119/128 [05:55<00:12,  1.37s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 120/128 [05:57<00:10,  1.36s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 121/128 [05:58<00:09,  1.36s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 122/128 [05:59<00:08,  1.37s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 123/128 [06:01<00:06,  1.37s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 124/128 [06:02<00:05,  1.36s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 125/128 [06:04<00:04,  1.38s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 126/128 [06:05<00:02,  1.37s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 127/128 [06:06<00:01,  1.37s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [06:07<00:00,  1.20s/it]***** Running Evaluation *****
  Num examples = 1004
  Batch size = 64
{'eval_loss': 1.0019128322601318, 'eval_runtime': 5.5622, 'eval_samples_per_second': 180.503, 'eval_steps_per_second': 2.877, 'epoch': 1.0}

  0%|          | 0/16 [00:00<?, ?it/s][A
 12%|â–ˆâ–Ž        | 2/16 [00:00<00:02,  5.73it/s][A
 19%|â–ˆâ–‰        | 3/16 [00:00<00:03,  4.04it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:01<00:03,  3.50it/s][A
 31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:01<00:03,  3.25it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:01<00:03,  3.09it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:02<00:03,  3.00it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:02<00:02,  2.93it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:02<00:02,  2.90it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 10/16 [00:03<00:02,  2.87it/s][A
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:03<00:01,  2.85it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:03<00:01,  2.84it/s][A
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:04<00:01,  2.83it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:04<00:00,  2.83it/s][A
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:04<00:00,  2.82it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:05<00:00,  3.09it/s][A                                                 
                                               [A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [06:13<00:00,  1.20s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:05<00:00,  3.09it/s][A
                                               [ASaving model checkpoint to results/checkpoints/20q/gpt2-xl/combined/checkpoint-128
Configuration saved in results/checkpoints/20q/gpt2-xl/combined/checkpoint-128/config.json
Model weights saved in results/checkpoints/20q/gpt2-xl/combined/checkpoint-128/pytorch_model.bin


Training completed. Do not forget to share your model on huggingface.co/models =)


Loading best model from results/checkpoints/20q/gpt2-xl/combined/checkpoint-64 (score: 1.0019128322601318).
                                                 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [11:50<00:00,  1.20s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [11:50<00:00,  5.55s/it]
***** Running Evaluation *****
  Num examples = 1004
  Batch size = 64
{'eval_loss': 1.0373870134353638, 'eval_runtime': 5.5544, 'eval_samples_per_second': 180.758, 'eval_steps_per_second': 2.881, 'epoch': 2.0}
{'train_runtime': 710.9546, 'train_samples_per_second': 11.421, 'train_steps_per_second': 0.18, 'train_loss': 0.9723568558692932, 'epoch': 2.0}
  0%|          | 0/16 [00:00<?, ?it/s] 12%|â–ˆâ–Ž        | 2/16 [00:00<00:02,  6.50it/s] 19%|â–ˆâ–‰        | 3/16 [00:00<00:02,  4.57it/s] 25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:00<00:03,  3.94it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:01<00:03,  3.64it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:01<00:02,  3.48it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:01<00:02,  3.38it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:02<00:02,  3.31it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:02<00:02,  3.26it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 10/16 [00:02<00:01,  3.23it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:03<00:01,  3.21it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:03<00:01,  3.19it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:03<00:00,  3.17it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:04<00:00,  3.16it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:04<00:00,  3.15it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:04<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:04<00:00,  3.44it/s]
Saving model checkpoint to results/best-checkpoints/20q/gpt2-xl/combined
Configuration saved in results/best-checkpoints/20q/gpt2-xl/combined/config.json
Model weights saved in results/best-checkpoints/20q/gpt2-xl/combined/pytorch_model.bin
{'eval_loss': 1.0019128322601318, 'eval_runtime': 4.9743, 'eval_samples_per_second': 201.837, 'eval_steps_per_second': 3.217, 'epoch': 2.0}
Loaded dataset with 4060 elements
Loaded dataset with 1004 elements
Loaded dataset with 5055 elements
train Accuracy =  0.7017241379310345
train F1 score =  0.8098413465005174
train Confusion Matrix =  [[1099   34]
 [   1 1750]]
Classification Report               precision    recall  f1-score   support

        6407       1.00      0.55      0.71      2014
       10352       0.98      0.86      0.91      2046

   micro avg       0.99      0.70      0.82      4060
   macro avg       0.99      0.70      0.81      4060
weighted avg       0.99      0.70      0.81      4060

valid Accuracy =  0.702191235059761
valid F1 score =  0.812849288242826
valid Confusion Matrix =  [[279   7]
 [  0 426]]
Classification Report               precision    recall  f1-score   support

        6407       1.00      0.56      0.71       502
       10352       0.98      0.85      0.91       502

   micro avg       0.99      0.70      0.82      1004
   macro avg       0.99      0.70      0.81      1004
weighted avg       0.99      0.70      0.81      1004

test Accuracy =  0.695351137487636
test F1 score =  0.805517415387504
test Confusion Matrix =  [[1371   42]
 [  10 2144]]
Classification Report               precision    recall  f1-score   support

        6407       0.99      0.55      0.71      2507
       10352       0.98      0.84      0.91      2548

   micro avg       0.99      0.70      0.82      5055
   macro avg       0.99      0.69      0.81      5055
weighted avg       0.99      0.70      0.81      5055

